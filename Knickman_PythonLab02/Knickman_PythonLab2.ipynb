{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert Celsius to Fahrenheit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a Celsius temp: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0  degrees Celsius converts to  32.0  degrees Fahrenheit\n"
     ]
    }
   ],
   "source": [
    "def celsius_to_fahrenheit(param_float):                                                                       \n",
    "    return param_float * 1.8 + 32.0\n",
    "\n",
    "print(\"Convert Celsius to Fahrenheit.\")\n",
    "cel_float = float(input(\"Enter a Celsius temp:\"))\n",
    "fah_float = celsius_to_fahrenheit(cel_float)\n",
    "print(cel_float,\" degrees Celsius converts to \",fah_float,\" degrees Fahrenheit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anagram Test\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter two space-separated words:  abc cba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words are anagrams.\n"
     ]
    }
   ],
   "source": [
    "def are_anagrams(word1, word2):\n",
    "    word1_sorted = sorted(word1)\n",
    "    word2_sorted = sorted(word2)\n",
    "    return word1_sorted == word2_sorted\n",
    "\n",
    "print(\"Anagram Test\")\n",
    "two_words = input(\"Enter two space-separated words: \")\n",
    "word1, word2 = two_words.split()\n",
    "\n",
    "if are_anagrams(word1,word2):\n",
    "    print(\"The words are anagrams.\")\n",
    "else:\n",
    "    print(\"The words are NOT anagrams.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Four', 'score', 'and', 'seven', 'years', 'ago', 'our', 'fathers', 'brought', 'forth', 'on', 'this', 'continent,', 'a', 'new', 'nation,', 'conceived', 'in', 'Liberty,', 'and', 'dedicated', 'to', 'the', 'proposition', 'that', 'all', 'men', 'are', 'created', 'equal.', 'Now', 'we', 'are', 'engaged', 'in', 'a', 'great', 'civil', 'war,', 'testing', 'whether', 'that', 'nation,', 'or', 'any', 'nation', 'so', 'conceived', 'and', 'dedicated,', 'can', 'long', 'endure.', 'We', 'are', 'met', 'on', 'a', 'great', 'battle-field', 'of', 'that', 'war.', 'We', 'have', 'come', 'to', 'dedicate', 'a', 'portion', 'of', 'that', 'field,', 'as', 'a', 'final', 'resting', 'place', 'for', 'those', 'who', 'here', 'gave', 'their', 'lives', 'that', 'that', 'nation', 'might', 'live.', 'It', 'is', 'altogether', 'fitting', 'and', 'proper', 'that', 'we', 'should', 'do', 'this.', 'But,', 'in', 'a', 'larger', 'sense,', 'we', 'can', 'not', 'dedicate', 'we', 'can', 'not', 'consecrate', 'we', 'can', 'not', 'hallow', 'this', 'ground.', 'The', 'brave', 'men,', 'living', 'and', 'dead,', 'who', 'struggled', 'here,', 'have', 'consecrated', 'it,', 'far', 'above', 'our', 'poor', 'power', 'to', 'add', 'or', 'detract.', 'The', 'world', 'will', 'little', 'note,', 'nor', 'long', 'remember', 'what', 'we', 'say', 'here,', 'but', 'it', 'can', 'never', 'forget', 'what', 'they', 'did', 'here.', 'It', 'is', 'for', 'us', 'the', 'living,', 'rather,', 'to', 'be', 'dedicated', 'here', 'to', 'the', 'unfinished', 'work', 'which', 'they', 'who', 'fought', 'here', 'have', 'thus', 'far', 'so', 'nobly', 'advanced.', 'It', 'is', 'rather', 'for', 'us', 'to', 'be', 'here', 'dedicated', 'to', 'the', 'great', 'task', 'remaining', 'before', 'us', 'that', 'from', 'these', 'honored', 'dead', 'we', 'take', 'increased', 'devotion', 'to', 'that', 'cause', 'for', 'which', 'they', 'gave', 'the', 'last', 'full', 'measure', 'of', 'devotion', 'that', 'we', 'here', 'highly', 'resolve', 'that', 'these', 'dead', 'shall', 'not', 'have', 'died', 'in', 'vain', 'that', 'this', 'nation,', 'under', 'God,', 'shall', 'have', 'a', 'new', 'birth', 'of', 'freedom', 'and', 'that', 'government', 'of', 'the', 'people,', 'by', 'the', 'people,', 'for', 'the', 'people,', 'shall', 'not', 'perish', 'from', 'the', 'earth.']\n",
      "Speech Length:  270\n",
      "Unique Length:  153\n"
     ]
    }
   ],
   "source": [
    "def make_word_list(a_file):\n",
    "    word_list = []\n",
    "    for line_str in a_file:\n",
    "        line_list = line_str.split()\n",
    "        for word in line_list:\n",
    "            if word != \"--\":\n",
    "                word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "def make_unique(word_list):\n",
    "    unique_list = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word not in unique_list:\n",
    "            unique_list.append(word)\n",
    "            \n",
    "    return unique_list\n",
    "\n",
    "gba_file = open(\"gettysburg.txt\",\"r\")\n",
    "speech_list = make_word_list(gba_file)\n",
    "\n",
    "print(speech_list)\n",
    "print(\"Speech Length: \", len(speech_list))\n",
    "print(\"Unique Length: \", len(make_unique(speech_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruoF erocs dna neves sraey oga ruo srehtaf thguorb htrof no siht ,tnenitnoc a wen ,noitan deviecnoc ni ,ytrebiL dna detacided ot eht noitisoporp taht lla nem era detaerc .lauqe woN ew era degagne ni a taerg livic ,raw gnitset rehtehw taht ,noitan ro yna noitan os deviecnoc dna ,detacided nac gnol .erudne eW era tem no a taerg dleif-elttab fo taht .raw eW evah emoc ot etacided a noitrop fo taht ,dleif sa a lanif gnitser ecalp rof esoht ohw ereh evag rieht sevil taht taht noitan thgim .evil tI si rehtegotla gnittif dna reporp taht ew dluohs od .siht ,tuB ni a regral ,esnes ew nac ton etacided ew nac ton etarcesnoc ew nac ton wollah siht .dnuorg ehT evarb ,nem gnivil dna ,daed ohw delggurts ,ereh evah detarcesnoc ,ti raf evoba ruo roop rewop ot dda ro .tcarted ehT dlrow lliw elttil ,eton ron gnol rebmemer tahw ew yas ,ereh tub ti nac reven tegrof tahw yeht did .ereh tI si rof su eht ,gnivil ,rehtar ot eb detacided ereh ot eht dehsinifnu krow hcihw yeht ohw thguof ereh evah suht raf os ylbon .decnavda tI si rehtar rof su ot eb ereh detacided ot eht taerg ksat gniniamer erofeb su taht morf eseht deronoh daed ew ekat desaercni noitoved ot taht esuac rof hcihw yeht evag eht tsal lluf erusaem fo noitoved taht ew ereh ylhgih evloser taht eseht daed llahs ton evah deid ni niav taht siht ,noitan rednu ,doG llahs evah a wen htrib fo modeerf dna taht tnemnrevog fo eht ,elpoep yb eht ,elpoep rof eht ,elpoep llahs ton hsirep morf eht .htrae\n"
     ]
    }
   ],
   "source": [
    "def reverse_doc(file):\n",
    "    doc_elems = []\n",
    "    for line_str in file:\n",
    "        line_list = line_str.split()\n",
    "        for word in line_list:\n",
    "            if word != \"--\":\n",
    "                doc_elems.append(word)\n",
    "    doc_elems\n",
    "    \n",
    "    rev_elems = []\n",
    "    \n",
    "    for elem in doc_elems:\n",
    "        rev_elems.append(elem[::-1])\n",
    "        \n",
    "    rev_elems\n",
    "    rev_doc = \" \".join(rev_elems)\n",
    "    return rev_doc\n",
    "\n",
    "speech_file = open(\"gettysburg.txt\",\"r\")\n",
    "print(reverse_doc(speech_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
